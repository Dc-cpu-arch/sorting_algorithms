Sorting Algorithms is a way of thinking,

It is necessary because we have to think in a sorted way,
we need to organize things alphabetically, numerically,
in ascending or descending order, and so on...

First we have to organize the data,
then we can think on it and process it as we want to.

If data is well sorted we can compare values faster and easyly

Some sorting algotirhms, as bubble sort, are just to think but don't work efficiently

We don't only need to sort the data,
we have to do it in a way that the computer could do it with the less space and time implied possible

With an array of 10 elements we can use bubble sort without a problem

But if we compare an array of 10 billion elements, we have to make our computer think on it about 10 billion mss
10 billion ms is a lot of seconds, minutes, hours, days and months.

Of course we have better algos to process that billions, trillions and so on, 

A Binary Search can process the same data in a logarithmic way, that is,
the more data processed, the less time left to get the data as we want

4 billion data is 4 billion operations to a bubble sort
4 billion data is 32 operations to a binary search

Thats when Big O gets in

Big O is a way to think about that data measures, and compare the aproximated time to process it in different algos

There is allways a best algo to process a given data set

Fortunatelly, we have lots of it.

We have all the algos we need at the moment to process the data we have at the moment

but, as informatic is sorcery, more data arrives us and we have to think about more algos to handle it

I think that data is predictable and algos are finite, but who knows?

How many ways to sleep, to write, to move, to fly, to read, to wash your hands...

We can imagine lots, but there are few that are appropiated to do the thing

There is allways a next logical step to move on
